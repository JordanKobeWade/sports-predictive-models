{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# While the entire program can be run, it is recommended that \"optional\" sections be ignored for cleaner output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_data = pd.read_csv('SampleTrainingData.csv')\n",
    "event_data = pd.read_csv('SamplePreraceData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_automation(regressor, params, x, y):\n",
    "    grid = GridSearchCV(estimator= regressor,\n",
    "                        param_grid= params,\n",
    "                        scoring = 'neg_mean_absolute_error',\n",
    "                        cv = 10,\n",
    "                        n_jobs = -1)\n",
    "    grid.fit(x, y)\n",
    "    print('Best Score:', -grid.best_score_)\n",
    "    best_params = grid.best_estimator_\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch parameters\n",
    "\n",
    "# RF\n",
    "rf_params = {\n",
    "    'n_estimators': [200,225,250,275],\n",
    "    'max_depth': [6],\n",
    "    'max_features' : ['auto'],\n",
    "    'max_leaf_nodes': [18,20,22]}\n",
    "\n",
    "# ET\n",
    "et_params = {\n",
    "    'n_estimators':[450,500,550], \n",
    "    'max_features': [0.75],\n",
    "    'max_depth': [9,10,11],\n",
    "    'min_samples_leaf': [2],\n",
    "    'max_leaf_nodes': [18,20,22]}    \n",
    "\n",
    "# GB\n",
    "gb_params = {'learning_rate': [0.03,0.04], \n",
    "              'n_estimators': [175, 200, 225],\n",
    "              'subsample':[0.9], \n",
    "              'max_depth': [3]}\n",
    "\n",
    "# AdaBoost\n",
    "ada_params = {'n_estimators':[2,3,4,5],\n",
    "    'learning_rate':[0.25, 0.4, 0.5]}\n",
    "\n",
    "# KNN\n",
    "knn_params = {'n_neighbors':[75]}\n",
    "\n",
    "# SVM\n",
    "svm_params = {'epsilon': [1.5, 2, 2.5],\n",
    "              'max_iter': [2250, 2500, 2750]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Data Preprocessing (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're dropping drivers' first races of the season, as such data will not have any predictive value.\n",
    "loop_data = loop_data.drop(loop_data[loop_data['race_number'] <= 1].index)\n",
    "loop_data = loop_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop drivers with only 5 races total, for the similar reason\n",
    "values = loop_data['driver'].value_counts().keys().tolist()\n",
    "counts = loop_data['driver'].value_counts().tolist()\n",
    "\n",
    "value_counts_df = pd.DataFrame(data=np.column_stack((values,counts)), index=range(len(values)), columns=['values', 'counts'])\n",
    "value_counts_df['counts'] = value_counts_df['counts'].astype('int32')\n",
    "value_counts_df = value_counts_df.loc[value_counts_df['counts'] < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_to_drop = value_counts_df['values'] \n",
    "\n",
    "index_array = []\n",
    "\n",
    "for dtd in drivers_to_drop:\n",
    "    for i, driver in enumerate(loop_data['driver']):\n",
    "        if driver == dtd:\n",
    "            index_array.append(i)\n",
    "            \n",
    "loop_data = loop_data.drop(index_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop instances without past_three_track_rating data \n",
    "# loop_data = loop_data.loc[loop_data['past_three_track_rating'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphViz (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data_to_plot = loop_data[['average_humidity', 'average_windspeed', 'fpts', 'previous_event_rating', 'rating_to_date']]\n",
    "data_to_plot.hist(bins=50, figsize=(10,7.5))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['fpts', 'start', 'track_total_laps', 'average_windspeed']\n",
    "pd.plotting.scatter_matrix(loop_data[attributes], figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['fpts', 'rating_to_date', 'previous_event_rating']\n",
    "pd.plotting.scatter_matrix(loop_data[attributes], figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = loop_data[['start', 'track_total_laps', 'track_lap_length','rating_to_date', 'past_three_track_rating', 'average_windspeed']]\n",
    "# x = loop_data[['start', 'track_total_laps', 'track_lap_length', 'average_windspeed', 'rating_to_date']]\n",
    "# x = pd.concat([x, loop_data[driver_dummies_columns]], axis=1)\n",
    "Y = loop_data[['fpts']]\n",
    "\n",
    "x_train, x_test, Y_train, Y_test = train_test_split(x,Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver_dummies = pd.get_dummies(loop_data['driver'])\n",
    "# loop_data = pd.concat([loop_data, driver_dummies], axis=1)\n",
    "\n",
    "# driver_dummies_columns = driver_dummies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_train_data = scaler.fit_transform(x_train)\n",
    "scaled_test_data = scaler.transform(x_test)\n",
    "\n",
    "scaled_x_train = pd.DataFrame(scaled_train_data, index=range(len(scaled_train_data)), columns=['start', 'track_total_laps', 'track_lap_length', 'rating_to_date', 'past_three_track_rating', 'average_windspeed'])\n",
    "scaled_x_test = pd.DataFrame(scaled_test_data, index=range(len(scaled_test_data)), columns=['start', 'track_total_laps', 'track_lap_length', 'rating_to_date', 'past_three_track_rating', 'average_windspeed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_correlation = loop_data[['start', 'track_total_laps', 'track_lap_length', 'average_windspeed', 'rating_to_date', 'previous_event_rating', 'fpts']]\n",
    "\n",
    "corr_matrix = for_correlation.corr()\n",
    "corr_matrix['fpts'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer 1 Model Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_params = grid_search_automation(RandomForestRegressor(), rf_params, scaled_x_train, Y_train.values.ravel())\n",
    "et_best_params = grid_search_automation(ExtraTreesRegressor(), et_params, scaled_x_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_best_params = grid_search_automation(LinearSVR(), svm_params, scaled_x_train, Y_train.values.ravel())\n",
    "ada_best_params = grid_search_automation(AdaBoostRegressor(), ada_params, scaled_x_train, Y_train.values.ravel())\n",
    "knn_best_params = grid_search_automation(KNeighborsRegressor(), knn_params, scaled_x_train, Y_train.values.ravel())\n",
    "gb_best_params = grid_search_automation(GradientBoostingRegressor(), gb_params, scaled_x_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the following result for the model parameters. \n",
    "# notice that with the way the program is currently written, they must be manually typed in\n",
    "\n",
    "print(rf_best_params)\n",
    "print(et_best_params)\n",
    "print(svm_best_params)\n",
    "print(ada_best_params)\n",
    "print(knn_best_params)\n",
    "print(gb_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer 1 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_forest = RandomForestRegressor(n_estimators=250, n_jobs=-1, max_leaf_nodes=None, max_depth=6)\n",
    "rnd_forest.fit(scaled_x_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_predictions = rnd_forest.predict(scaled_x_train)\n",
    "rf_test_predictions = rnd_forest.predict(scaled_x_test)\n",
    "train_mae = mean_absolute_error(Y_train, rf_train_predictions)\n",
    "test_mae = mean_absolute_error(Y_test, rf_test_predictions)\n",
    "print('Train MAE:', train_mae)\n",
    "print('Test MAE:', test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rnd_forest, scaled_x_train, Y_train.values.ravel(), scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "rf_mae_scores = -scores\n",
    "print('CV Error:', np.mean(rf_mae_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv_predictions = cross_val_predict(rnd_forest, scaled_x_train, Y_train.values.ravel(), cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(scaled_x_train))\n",
    "print(len(loop_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_trees = ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=10,\n",
    "          max_features=0.75, max_leaf_nodes=None,\n",
    "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "          min_samples_leaf=3, min_samples_split=2,\n",
    "          min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
    "          oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
    "extra_trees.fit(scaled_x_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_train_predictions = extra_trees.predict(scaled_x_train)\n",
    "et_test_predictions = extra_trees.predict(scaled_x_test)\n",
    "train_mae = mean_absolute_error(Y_train, et_train_predictions)\n",
    "test_mae = mean_absolute_error(Y_test, et_test_predictions)\n",
    "print('Train MAE:', train_mae)\n",
    "print('Test MAE:', test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(extra_trees, scaled_x_train, Y_train.values.ravel(), scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "et_mae_scores = -scores\n",
    "print('CV Error:', np.mean(et_mae_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_cv_predictions = cross_val_predict(extra_trees, scaled_x_train, Y_train.values.ravel(), cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_reg = LinearSVR(C=1.0, dual=True, epsilon=2, fit_intercept=True,\n",
    "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=2500,\n",
    "     random_state=None, tol=0.0001, verbose=0)\n",
    "svm_reg.fit(scaled_x_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_train_predictions = svm_reg.predict(scaled_x_train)\n",
    "svm_test_predictions = svm_reg.predict(scaled_x_test)\n",
    "train_mae = mean_absolute_error(Y_train, svm_train_predictions)\n",
    "test_mae = mean_absolute_error(Y_test, svm_test_predictions)\n",
    "print('Train MAE:', train_mae)\n",
    "print('Test MAE:', test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(svm_reg, scaled_x_train, Y_train.values.ravel(), scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "svm_mae_scores = -scores\n",
    "print('CV Error:', np.mean(svm_mae_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cv_predictions = cross_val_predict(svm_reg, scaled_x_train, Y_train.values.ravel(), cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost = AdaBoostRegressor(DecisionTreeRegressor(max_depth=2), n_estimators=10, learning_rate=0.5, random_state=42)\n",
    "ada_boost.fit(scaled_x_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_train_predictions = ada_boost.predict(scaled_x_train)\n",
    "ada_test_predictions = ada_boost.predict(scaled_x_test)\n",
    "train_mae = mean_absolute_error(Y_train, ada_train_predictions)\n",
    "test_mae = mean_absolute_error(Y_test, ada_test_predictions)\n",
    "print('Train MAE:', train_mae)\n",
    "print('Test MAE:', test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(ada_boost, scaled_x_train, Y_train.values.ravel(), scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "ada_mae_scores = -scores\n",
    "print('CV Error:', np.mean(ada_mae_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_cv_predictions = cross_val_predict(ada_boost, scaled_x_train, Y_train.values.ravel(), cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "          metric_params=None, n_jobs=1, n_neighbors=75, p=2,\n",
    "          weights='uniform')\n",
    "knn.fit(scaled_x_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train_predictions = knn.predict(scaled_x_train)\n",
    "knn_test_predictions = knn.predict(scaled_x_test)\n",
    "train_mae = mean_absolute_error(Y_train, knn_train_predictions)\n",
    "test_mae = mean_absolute_error(Y_test, knn_test_predictions)\n",
    "print('Train MAE:', train_mae)\n",
    "print('Test MAE:', test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(knn, scaled_x_train, Y_train.values.ravel(), scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "knn_mae_scores = -scores\n",
    "print('CV Error:', np.mean(knn_mae_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv_predictions = cross_val_predict(knn, scaled_x_train, Y_train.values.ravel(), cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_reg = GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
    "             learning_rate=0.04, loss='ls', max_depth=3, max_features=None,\n",
    "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "             min_impurity_split=None, min_samples_leaf=1,\n",
    "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "             n_estimators=200, presort='auto', random_state=None,\n",
    "             subsample=0.9, verbose=0, warm_start=False)\n",
    "gb_reg.fit(scaled_x_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_train_predictions = gb_reg.predict(scaled_x_train)\n",
    "gb_test_predictions = gb_reg.predict(scaled_x_test)\n",
    "train_mae = mean_absolute_error(Y_train, gb_train_predictions)\n",
    "test_mae = mean_absolute_error(Y_test, gb_test_predictions)\n",
    "print('Train MAE:', train_mae)\n",
    "print('Test MAE:', test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(gb_reg, scaled_x_train, Y_train.values.ravel(), scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "gb_mae_scores = -scores\n",
    "print('CV Error:', np.mean(gb_mae_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_cv_predictions = cross_val_predict(gb_reg, scaled_x_train, Y_train.values.ravel(), cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Predictions For New Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_prediction_df = pd.DataFrame(data=np.column_stack((rf_cv_predictions, et_cv_predictions, svm_cv_predictions, gb_cv_predictions, knn_cv_predictions)), index=range(len(rf_cv_predictions)), columns=['rf', 'et', 'svm', 'gb', 'knn'])\n",
    "test_prediction_df = pd.DataFrame(data=np.column_stack((rf_test_predictions, et_test_predictions, svm_test_predictions, gb_test_predictions, knn_test_predictions)), index=range(len(rf_test_predictions)), columns=['rf', 'et', 'svm', 'gb', 'knn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_train = pd.concat([scaled_x_train, cv_prediction_df], axis = 1)\n",
    "scaled_x_test = pd.concat([scaled_x_test, test_prediction_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV (Run if you don't know your optimal hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators': [500,750,1000,1100,1200],\n",
    "     'learning_rate': [0.011, 0.012, 0.013],\n",
    "     'subsample': [0.7,0.9],\n",
    "     'max_depths': [6]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_model = XGBRegressor(booster='gbtree', objective ='reg:squarederror', n_jobs=-1)\n",
    "grid_search = GridSearchCV(boost_model, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(scaled_x_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_model = XGBRegressor(booster='gbtree', verbosity=0, n_estimators= 500, learning_rate = 0.011, subsample = 0.9, max_depths= 2, n_jobs=-1, colsample_bytree=0.8, gamma=1, objective ='reg:squarederror')\n",
    "my_model.fit(scaled_x_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# features = x_train.columns\n",
    "# feature_importances = my_model.feature_importances_\n",
    "# features_index = range(len(features))\n",
    "# features_df = pd.DataFrame(np.nan, index= features_index, columns = ['features', 'feature_importances'])\n",
    "# features_df['features'] = features\n",
    "# features_df['feature_importances'] = feature_importances\n",
    "\n",
    "# features_df.sort_values(by=['feature_importances'], ascending=False)\n",
    "# print(features_df)\n",
    "\n",
    "pyplot.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "plot_importance(my_model)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = my_model.predict(scaled_x_train)\n",
    "train_mae = mean_absolute_error(Y_train, train_results)\n",
    "print('Train Error: ' + str(train_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(my_model, scaled_x_train, Y_train, scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "tree_mae_scores = -scores\n",
    "print('CV Error:', np.mean(tree_mae_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = my_model.predict(scaled_x_test)\n",
    "test_mae_score = mean_absolute_error(Y_test, test_predictions)\n",
    "print('Test Error:', str(test_mae_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = scaled_x_test[['rf', 'et', 'svm', 'gb', 'knn']]\n",
    "\n",
    "corr_matrix = correlation.corr()\n",
    "corr_matrix['rf'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_event = event_data[['start', 'track_total_laps', 'rating_to_date', 'past_three_track_rating', 'average_windspeed']]\n",
    "# x_event = pd.concat([x_event, event_data[driver_dummies_columns]], axis=1)\n",
    "\n",
    "print(x.columns)\n",
    "print(x_event.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_event_data = scaler.fit_transform(x_event)\n",
    "\n",
    "scaled_x_event = pd.DataFrame(scaled_event_data, index=range(len(scaled_event_data)), columns=['start', 'track_total_laps', 'rating_to_date', 'past_three_track_rating', 'average_windspeed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_event_predictions = rnd_forest.predict(scaled_x_event)\n",
    "et_event_predictions = extra_trees.predict(scaled_x_event)\n",
    "svm_event_predictions = svm_reg.predict(scaled_x_event)\n",
    "ada_event_predictions = ada_boost.predict(scaled_x_event)\n",
    "gb_event_predictions = gb_reg.predict(scaled_x_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_prediction_df = pd.DataFrame(data=np.column_stack((rf_event_predictions, et_event_predictions, svm_event_predictions, ada_event_predictions, gb_event_predictions)), index=range(len(rf_event_predictions)), columns=['rf', 'et', 'svm', 'ada', 'gb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_event = pd.concat([scaled_x_event, event_prediction_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_predictions = my_model.predict(scaled_x_event)\n",
    "event_predictions_draft= x_event.copy()\n",
    "event_predictions_draft['fpts'] = event_predictions\n",
    "event_predictions_draft['driver'] = event_data['driver']\n",
    "event_predictions_complete = event_predictions_draft[['start', 'fpts', 'driver']]\n",
    "event_predictions_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
